{"tagline":"Easy way to retrieve Google Page Rank, Alexa Rank, index counts, and backlink counts","google":"UA-33059328-1","note":"Don't delete this file! It's used internally to help with page regeneration.","name":"Page rankr","body":"[![Build Status](http://travis-ci.org/blatyo/page_rankr.png)](http://travis-ci.org/blatyo/page_rankr)\r\nProvides an easy way to retrieve Google Page Rank, Alexa Rank, backlink counts, and index counts.\r\n\r\nCheck out a little [web app][1] I wrote up that uses it or look at the [source][2].\r\n\r\n[1]: http://isitpopular.heroku.com\r\n[2]: https://github.com/blatyo/is_it_popular\r\n\r\n## Get it!\r\n\r\n``` bash\r\ngem install PageRankr\r\n```\r\n\r\n## Use it!\r\n\r\n``` ruby\r\nrequire 'page_rankr'\r\n```\r\n\r\n### Backlinks\r\n\r\nBacklinks are the result of doing a search with a query like \"link:www.google.com\". The number of returned results indicates how many sites point to that url. If a site is not tracked then `nil` is returned.\r\n\r\n``` ruby\r\nPageRankr.backlinks('www.google.com', :google, :bing) #=> {:google=>161000, :bing=>208000000}\r\nPageRankr.backlinks('www.google.com', :yahoo)         #=> {:yahoo=>256300062}\r\n```\r\n\r\nIf you don't specify a search engine, then all of them are used.\r\n\r\n``` ruby\r\n# this\r\nPageRankr.backlinks('www.google.com')\r\n    #=> {:google=>23000, :bing=>215000000, :yahoo=>250522337, :alexa=>727036}\r\n\r\n# is equivalent to\r\nPageRankr.backlinks('www.google.com', :google, :bing, :yahoo, :alexa)\r\n    #=> {:google=>23000, :bing=>215000000, :yahoo=>250522337, :alexa=>727036}\r\n```\r\n\r\nYou can also use the alias `backlink` instead of `backlinks`.\r\n\r\nValid search engines are: `:google, :bing, :yahoo, :alexa` (altavista and alltheweb now redirect to yahoo). To get this list you can do:\r\n\r\n``` ruby\r\nPageRankr.backlink_trackers #=> [:alexa, :bing, :google, :yahoo]\r\n```\r\n\r\n### Indexes\r\n\r\nIndexes are the result of doing a search with a query like \"site:www.google.com\". The number of returned results indicates how many pages of a domain are indexed by a particular search engine. If the site is not indexed `nil` is returned.\r\n\r\n``` ruby\r\nPageRankr.indexes('www.google.com', :google)       #=> {:google=>4860000}\r\nPageRankr.indexes('www.google.com', :bing)         #=> {:bing=>2120000}\r\n```\r\n\r\nIf you don't specify a search engine, then all of them are used.\r\n\r\n``` ruby\r\n# this\r\nPageRankr.indexes('www.google.com')\r\n    #=> {:bing=>2120000, :google=>4860000, :yahoo => 4863000}\r\n\r\n# is equivalent to\r\nPageRankr.indexes('www.google.com', :google, :bing, :yahoo)\r\n    #=> {:bing=>2120000, :google=>4860000, :yahoo => 4863000}\r\n```\r\n\r\nYou can also use the alias `index` instead of `indexes`.\r\n\r\nValid search engines are: `:google, :bing, :yahoo`. To get this list you can do:\r\n\r\n``` ruby\r\nPageRankr.index_trackers #=> [:bing, :google, :yahoo]\r\n```\r\n\r\n### Ranks\r\n\r\nRanks are ratings assigned to specify how popular a site is. The most famous example of this is the google page rank.\r\n\r\n``` ruby\r\nPageRankr.ranks('www.google.com', :google)        #=> {:google=>10}\r\n```\r\n\r\nIf you don't specify a rank provider, then all of them are used.\r\n\r\n``` ruby\r\nPageRankr.ranks('www.google.com', :alexa_us, :alexa_global, :google)\r\n    #=> {:alexa_us=>1, :alexa_global=>1, :google=>10}\r\n\r\n# this also gives the same result\r\nPageRankr.ranks('www.google.com')\r\n    #=> {:alexa_us=>1, :alexa_global=>1, :google=>10}\r\n```\r\n\r\nYou can also use the alias `rank` instead of `ranks`.\r\n\r\nValid rank trackers are: `:alexa_us, :alexa_global, :google`. To get this you can do:\r\n\r\n``` ruby\r\nPageRankr.rank_trackers #=> [:alexa_global, :alexa_us, :google]\r\n```\r\n\r\nAlexa ranks are descending where 1 is the most popular. Google page ranks are in the range 0-10 where 10 is the most popular. If a site is unindexed then the rank will be nil.\r\n\r\n## Use it a la carte!\r\n\r\nFrom versions >= 3, everything should be usable in a much more a la carte manner. If all you care about is google page rank (which I speculate is common) you can get that all by itself:\r\n\r\n``` ruby\r\nrequire 'page_rankr/ranks/google'\r\n\r\ntracker = PageRankr::Ranks::Google.new(\"myawesomesite.com\")\r\ntracker.run #=> 2\r\n```\r\n\r\nAlso, once a tracker has run three values will be accessible from it:\r\n\r\n``` ruby\r\n# The value extracted. Tracked is aliased to rank for PageRankr::Ranks, backlink for PageRankr::Backlinks, and index for PageRankr::Indexes.\r\ntracker.tracked #=> 2\r\n\r\n# The value extracted with the jsonpath, xpath, or regex before being cleaned.\r\ntracker.raw     #=> \"2\"\r\n\r\n# The body of the response\r\ntracker.body    #=> \"<html><head>...\"\r\n```\r\n\r\n## Rate limiting and proxies\r\n\r\nOne of the annoying things about each of these services is that they really don't like you scraping data from them. In order to deal with this issue, they throttle traffic from a single machine. The simplest way to get around this is to use proxy machines to make the requests. \r\n\r\nIn PageRankr >= 3.2.0, this is much simpler. The first thing you'll need is a proxy service. Two are provided [here](https://github.com/blatyo/page_rankr/tree/master/lib/page_rankr/proxy_services). A proxy service must define a `proxy` method that takes two arguments. It should return a string like `user:password@192.168.1.1:50501`.\r\n\r\nOnce you have a proxy service, you can tell PageRankr to use it. For example:\r\n\r\n``` ruby\r\nPageRankr.proxy_service = PageRankr::ProxyServices::Random.new([\r\n  'user:password@192.168.1.1:50501',\r\n  'user:password@192.168.1.2:50501'\r\n])\r\n```\r\n\r\nOnce PageRankr knows about your proxy service, any request that is made will ask for a proxy from the proxy service. It does this by calling the `proxy` method. When it calls the `proxy` method, it passed the name of the tracker (e.g. `:ranks_google`) and the site that is being looked up. Hopefully, this information is sufficient for you to build a much smarter proxy service than the ones provided (pull requests welcome!).\r\n\r\n## Fix it!\r\n\r\nIf you ever find something is broken it should now be much easier to fix it with version >= 1.3.0. For example, if the xpath used to lookup a backlink is broken, just override the method for that class to provide the correct xpath.\r\n\r\n``` ruby\r\nmodule PageRankr\r\n  class Backlinks\r\n    class Bing\r\n      def xpath\r\n        \"//my/new/awesome/@xpath\"\r\n      end\r\n    end\r\n  end\r\nend\r\n```\r\n\r\n## Extend it!\r\n\r\nIf you ever come across a site that provides a rank or backlinks you can hook that class up to automatically be use with PageRankr. PageRankr does this by looking up all the classes namespaced under Backlinks, Indexes, and Ranks.\r\n\r\n``` ruby\r\nrequire 'page_rankr/backlink'\r\n\r\nmodule PageRankr\r\n  class Backlinks\r\n    class Foo\r\n      include Backlink\r\n\r\n      # This method is required\r\n      def url\r\n        \"http://example.com/\"\r\n      end\r\n\r\n      # This method specifies the parameters for the url. It is optional, but likely required for the class to be useful.\r\n      def params\r\n        {:q => tracked_url}\r\n      end\r\n\r\n      # You can use a method named either xpath, jsonpath, or regex with the appropriate query type\r\n      def xpath\r\n        \"//backlinks/text()\"\r\n      end\r\n\r\n      # Optionally, you could override the clean method if the current implementation isn't sufficient\r\n      # def clean(backlink_count)\r\n      #   #do some of my own cleaning\r\n      #   super(backlink_count) # strips non-digits and converts it to an integer or nil\r\n      # end\r\n    end\r\n  end\r\nend\r\n\r\nPageRankr::Backlinks::Foo.new(\"myawesomesite.com\").run #=> 3\r\nPageRankr.backlinks(\"myawesomesite.com\", :foo)[:foo]   #=> 3\r\n```\r\n\r\nThen, just make sure you require the class and PageRankr and whenever you call PageRankr.backlinks it'll be able to use your class.\r\n\r\n## Note on Patches/Pull Requests\r\n\r\n* Fork the project.\r\n* Make your feature addition or bug fix.\r\n* Add tests for it. This is important so I don't break it in a\r\n  future version unintentionally.\r\n* Commit, do not mess with rakefile, version, or history.\r\n  (if you want to have your own version, that is fine but bump version in a commit by itself I can ignore when I pull)\r\n* Send me a pull request. Bonus points for topic branches.\r\n\r\n## TODO Version 4\r\n* Detect request throttling\r\n\r\n## Contributors\r\n* [Dru Ibarra](https://github.com/Druwerd) - Use Google Search API instead of scraping.\r\n* [Iteration Labs, LLC](https://github.com/iterationlabs) - Compete rank tracker and domain indexes.\r\n* [Marc Seeger](http://www.marc-seeger.de) ([Acquia](http://www.acquia.com)) - Ignore invalid ranks that Alexa returns for incorrect sites.\r\n* [RÃ©my Coutable](https://github.com/rymai) - Update public_suffix_service gem.\r\n* [Jonathan Rudenberg](https://github.com/titanous) - Fix compete scraper.\r\n* [Chris Corbyn](https://github.com/d11wtq) - Fix google page rank url.\r\n* [Hans Haselberg](https://github.com/i0rek) - Update typhoeus gem.\r\n* [Priit Haamer](https://github.com/priithaamer) - Fix google backlinks lookup.\r\n* [Marty McKenna](https://github.com/martyMM) - Idea for proxy service\r\n\r\n## Shout Out\r\nGotta give credit where credits due!\r\n\r\nOriginal inspiration from:\r\n\r\n* [PageRankSharp](https://github.com/alexmipego/PageRankSharp)\r\n* [Google Page Range Lookup/](http://snipplr.com/view/18329/google-page-range-lookup/)\r\n* [AJAX PR Checker](http://www.sitetoolcenter.com/free-website-scripts/ajax-pr-checker.php)\r\n\r\n## Copyright\r\n\r\nCopyright (c) 2010 Allen Madsen. See LICENSE for details."}